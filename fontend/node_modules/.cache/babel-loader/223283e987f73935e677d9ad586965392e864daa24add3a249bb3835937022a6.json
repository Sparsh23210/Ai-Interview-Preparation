{"ast":null,"code":"// // src/components/EnglishLearningForm.js\n// import React, { useState, useEffect, useRef } from \"react\";\n// import axios from \"axios\";\n// import SpeechRecognition, { useSpeechRecognition } from \"react-speech-recognition\";\n// import  webgazer from \"webgazer\";\n\n// const EnglishLearningForm = () => {\n//   const [aiQuestion, setAiQuestion] = useState(\"\");\n//   const [loading, setLoading] = useState(false);\n//   const [analysis, setAnalysis] = useState(null);\n//   const [questionNumber, setQuestionNumber] = useState(1);\n//   const [questionHistory, setQuestionHistory] = useState(new Set());\n//   const videoRef = useRef(null);\n\n//   const {\n//     transcript,\n//     listening,\n//     resetTranscript,\n//     browserSupportsSpeechRecognition,\n//   } = useSpeechRecognition();\n\n//   const fetchUniqueQuestion = async () => {\n//     const maxRetries = 5;\n//     for (let i = 0; i < maxRetries; i++) {\n//       const response = await axios.get(\"http://localhost:5000/api/english-learning-question\");\n//       const newQuestion = response.data.question;\n//       if (!questionHistory.has(newQuestion)) {\n//         setQuestionHistory((prev) => new Set(prev).add(newQuestion));\n//         return newQuestion;\n//       }\n//     }\n//     return \"Unable to generate a unique question. Please try again later.\";\n//   };\n\n//   const handleStart = async () => {\n//     setLoading(true);\n//     try {\n//       const question = await fetchUniqueQuestion();\n//       setAiQuestion(question);\n//       resetTranscript();\n//       setAnalysis(null);\n//     } catch (error) {\n//       console.error(\"Error fetching AI question:\", error);\n//     }\n//     setLoading(false);\n//   };\n\n//   const startListening = () => {\n//     resetTranscript();\n//     SpeechRecognition.startListening({ continuous: true });\n//   };\n\n//   const stopListening = () => {\n//     SpeechRecognition.stopListening();\n//   };\n\n//   const analyzeTranscript = async () => {\n//     try {\n//       const response = await axios.post(\"http://localhost:5000/api/analyze-answer\", { text: transcript });\n//       setAnalysis(response.data);\n//     } catch (error) {\n//       console.error(\"Error analyzing transcript:\", error);\n//     }\n//   };\n\n//   useEffect(() => {\n//     if (!listening && transcript) {\n//       analyzeTranscript();\n//     }\n//   }, [listening]);\n\n//   const handleNextQuestion = async () => {\n//     setLoading(true);\n//     try {\n//       const question = await fetchUniqueQuestion();\n//       setAiQuestion(question);\n//       resetTranscript();\n//       setAnalysis(null);\n//       setQuestionNumber((prev) => prev + 1);\n//     } catch (error) {\n//       console.error(\"Error generating next question:\", error);\n//     }\n//     setLoading(false);\n//   };\n\n//   const startCamera = async () => {\n//     try {\n//       const stream = await navigator.mediaDevices.getUserMedia({ video: true });\n//       if (videoRef.current) {\n//         videoRef.current.srcObject = stream;\n//       }\n//     } catch (err) {\n//       console.error(\"Camera access denied or not available\", err);\n//     }\n//   };\n\n//   const startEyeTracking = () => {\n//     webgazer.setGazeListener((data, elapsedTime) => {\n//       if (data) {\n//         console.log(\"Gaze at:\", data.x, data.y);\n//       }\n//     }).begin();\n\n//     webgazer.showVideo(false).showFaceOverlay(false).showFaceFeedbackBox(false);\n//   };\n\n//   useEffect(() => {\n//     startCamera();\n//     startEyeTracking();\n//   }, []);\n\n//   if (!browserSupportsSpeechRecognition) {\n//     return <span>Your browser does not support speech recognition.</span>;\n//   }\n\n//   return (\n//     <div className=\"bg-white shadow-lg rounded-2xl p-6 max-w-2xl mx-auto mt-10\">\n//       <h2 className=\"text-2xl font-bold mb-4\">English Learning Assistant</h2>\n\n//       {/* üëÅÔ∏è Eye-Tracking Camera Feed */}\n//       <div className=\"mb-4\">\n//         <h4 className=\"text-lg font-semibold\">üì∑ Eye Tracking Camera (Live)</h4>\n//         <video ref={videoRef} autoPlay playsInline className=\"w-full max-h-56 rounded border\" />\n//       </div>\n\n//       <button\n//         onClick={handleStart}\n//         className=\"bg-blue-600 text-white px-4 py-2 rounded hover:bg-blue-700 mb-4\"\n//       >\n//         {loading ? \"Generating...\" : \"Start Practice\"}\n//       </button>\n\n//       {aiQuestion && (\n//         <div className=\"mt-4 p-4 bg-green-100 rounded-md\">\n//           <h3 className=\"font-semibold text-lg\">üìò Question {questionNumber}:</h3>\n//           <p>{aiQuestion}</p>\n\n//           <div className=\"mt-4\">\n//             <h4 className=\"font-semibold\">üé§ Your Answer (Voice Input)</h4>\n//             <p className=\"text-gray-700 mb-2\">{transcript || \"Your speech will appear here...\"}</p>\n//             <div className=\"flex gap-4\">\n//               <button onClick={startListening} className=\"bg-blue-500 text-white px-3 py-1 rounded hover:bg-blue-600\">\n//                 Start Talking\n//               </button>\n//               <button onClick={stopListening} className=\"bg-red-500 text-white px-3 py-1 rounded hover:bg-red-600\">\n//                 Stop\n//               </button>\n//               <button onClick={resetTranscript} className=\"bg-gray-300 px-3 py-1 rounded hover:bg-gray-400\">\n//                 Reset\n//               </button>\n//             </div>\n//           </div>\n\n//           {analysis && (\n//             <div className=\"mt-6 p-4 bg-yellow-100 rounded-md\">\n//               <h4 className=\"font-semibold text-lg\">üìä Answer Analysis</h4>\n//               <p>Fluency Score: {analysis.fluency}%</p>\n//               <p>Grammar Accuracy: {analysis.grammar}%</p>\n//               <p className=\"mt-2 text-right\">\n//                 <button onClick={handleNextQuestion} className=\"mt-2 bg-indigo-600 text-white px-4 py-2 rounded hover:bg-indigo-700\">\n//                   Next Question\n//                 </button>\n//               </p>\n//             </div>\n//           )}\n//         </div>\n//       )}\n//     </div>\n//   );\n// };\n\n// export default EnglishLearningForm;","map":{"version":3,"names":[],"sources":["C:/Users/Sparsh Chaurasiya/OneDrive/Desktop/react/student-ai-preparation/fontend/src/components/EnglishLearning.js"],"sourcesContent":["// // src/components/EnglishLearningForm.js\r\n// import React, { useState, useEffect, useRef } from \"react\";\r\n// import axios from \"axios\";\r\n// import SpeechRecognition, { useSpeechRecognition } from \"react-speech-recognition\";\r\n// import  webgazer from \"webgazer\";\r\n\r\n// const EnglishLearningForm = () => {\r\n//   const [aiQuestion, setAiQuestion] = useState(\"\");\r\n//   const [loading, setLoading] = useState(false);\r\n//   const [analysis, setAnalysis] = useState(null);\r\n//   const [questionNumber, setQuestionNumber] = useState(1);\r\n//   const [questionHistory, setQuestionHistory] = useState(new Set());\r\n//   const videoRef = useRef(null);\r\n\r\n//   const {\r\n//     transcript,\r\n//     listening,\r\n//     resetTranscript,\r\n//     browserSupportsSpeechRecognition,\r\n//   } = useSpeechRecognition();\r\n\r\n//   const fetchUniqueQuestion = async () => {\r\n//     const maxRetries = 5;\r\n//     for (let i = 0; i < maxRetries; i++) {\r\n//       const response = await axios.get(\"http://localhost:5000/api/english-learning-question\");\r\n//       const newQuestion = response.data.question;\r\n//       if (!questionHistory.has(newQuestion)) {\r\n//         setQuestionHistory((prev) => new Set(prev).add(newQuestion));\r\n//         return newQuestion;\r\n//       }\r\n//     }\r\n//     return \"Unable to generate a unique question. Please try again later.\";\r\n//   };\r\n\r\n//   const handleStart = async () => {\r\n//     setLoading(true);\r\n//     try {\r\n//       const question = await fetchUniqueQuestion();\r\n//       setAiQuestion(question);\r\n//       resetTranscript();\r\n//       setAnalysis(null);\r\n//     } catch (error) {\r\n//       console.error(\"Error fetching AI question:\", error);\r\n//     }\r\n//     setLoading(false);\r\n//   };\r\n\r\n//   const startListening = () => {\r\n//     resetTranscript();\r\n//     SpeechRecognition.startListening({ continuous: true });\r\n//   };\r\n\r\n//   const stopListening = () => {\r\n//     SpeechRecognition.stopListening();\r\n//   };\r\n\r\n//   const analyzeTranscript = async () => {\r\n//     try {\r\n//       const response = await axios.post(\"http://localhost:5000/api/analyze-answer\", { text: transcript });\r\n//       setAnalysis(response.data);\r\n//     } catch (error) {\r\n//       console.error(\"Error analyzing transcript:\", error);\r\n//     }\r\n//   };\r\n\r\n//   useEffect(() => {\r\n//     if (!listening && transcript) {\r\n//       analyzeTranscript();\r\n//     }\r\n//   }, [listening]);\r\n\r\n//   const handleNextQuestion = async () => {\r\n//     setLoading(true);\r\n//     try {\r\n//       const question = await fetchUniqueQuestion();\r\n//       setAiQuestion(question);\r\n//       resetTranscript();\r\n//       setAnalysis(null);\r\n//       setQuestionNumber((prev) => prev + 1);\r\n//     } catch (error) {\r\n//       console.error(\"Error generating next question:\", error);\r\n//     }\r\n//     setLoading(false);\r\n//   };\r\n\r\n//   const startCamera = async () => {\r\n//     try {\r\n//       const stream = await navigator.mediaDevices.getUserMedia({ video: true });\r\n//       if (videoRef.current) {\r\n//         videoRef.current.srcObject = stream;\r\n//       }\r\n//     } catch (err) {\r\n//       console.error(\"Camera access denied or not available\", err);\r\n//     }\r\n//   };\r\n\r\n//   const startEyeTracking = () => {\r\n//     webgazer.setGazeListener((data, elapsedTime) => {\r\n//       if (data) {\r\n//         console.log(\"Gaze at:\", data.x, data.y);\r\n//       }\r\n//     }).begin();\r\n\r\n//     webgazer.showVideo(false).showFaceOverlay(false).showFaceFeedbackBox(false);\r\n//   };\r\n\r\n//   useEffect(() => {\r\n//     startCamera();\r\n//     startEyeTracking();\r\n//   }, []);\r\n\r\n//   if (!browserSupportsSpeechRecognition) {\r\n//     return <span>Your browser does not support speech recognition.</span>;\r\n//   }\r\n\r\n//   return (\r\n//     <div className=\"bg-white shadow-lg rounded-2xl p-6 max-w-2xl mx-auto mt-10\">\r\n//       <h2 className=\"text-2xl font-bold mb-4\">English Learning Assistant</h2>\r\n\r\n//       {/* üëÅÔ∏è Eye-Tracking Camera Feed */}\r\n//       <div className=\"mb-4\">\r\n//         <h4 className=\"text-lg font-semibold\">üì∑ Eye Tracking Camera (Live)</h4>\r\n//         <video ref={videoRef} autoPlay playsInline className=\"w-full max-h-56 rounded border\" />\r\n//       </div>\r\n\r\n//       <button\r\n//         onClick={handleStart}\r\n//         className=\"bg-blue-600 text-white px-4 py-2 rounded hover:bg-blue-700 mb-4\"\r\n//       >\r\n//         {loading ? \"Generating...\" : \"Start Practice\"}\r\n//       </button>\r\n\r\n//       {aiQuestion && (\r\n//         <div className=\"mt-4 p-4 bg-green-100 rounded-md\">\r\n//           <h3 className=\"font-semibold text-lg\">üìò Question {questionNumber}:</h3>\r\n//           <p>{aiQuestion}</p>\r\n\r\n//           <div className=\"mt-4\">\r\n//             <h4 className=\"font-semibold\">üé§ Your Answer (Voice Input)</h4>\r\n//             <p className=\"text-gray-700 mb-2\">{transcript || \"Your speech will appear here...\"}</p>\r\n//             <div className=\"flex gap-4\">\r\n//               <button onClick={startListening} className=\"bg-blue-500 text-white px-3 py-1 rounded hover:bg-blue-600\">\r\n//                 Start Talking\r\n//               </button>\r\n//               <button onClick={stopListening} className=\"bg-red-500 text-white px-3 py-1 rounded hover:bg-red-600\">\r\n//                 Stop\r\n//               </button>\r\n//               <button onClick={resetTranscript} className=\"bg-gray-300 px-3 py-1 rounded hover:bg-gray-400\">\r\n//                 Reset\r\n//               </button>\r\n//             </div>\r\n//           </div>\r\n\r\n//           {analysis && (\r\n//             <div className=\"mt-6 p-4 bg-yellow-100 rounded-md\">\r\n//               <h4 className=\"font-semibold text-lg\">üìä Answer Analysis</h4>\r\n//               <p>Fluency Score: {analysis.fluency}%</p>\r\n//               <p>Grammar Accuracy: {analysis.grammar}%</p>\r\n//               <p className=\"mt-2 text-right\">\r\n//                 <button onClick={handleNextQuestion} className=\"mt-2 bg-indigo-600 text-white px-4 py-2 rounded hover:bg-indigo-700\">\r\n//                   Next Question\r\n//                 </button>\r\n//               </p>\r\n//             </div>\r\n//           )}\r\n//         </div>\r\n//       )}\r\n//     </div>\r\n//   );\r\n// };\r\n\r\n// export default EnglishLearningForm;\r\n"],"mappings":"AAAA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}